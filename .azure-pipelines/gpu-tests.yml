# Python package
# Create and test a Python package on multiple Python versions.
# Add steps that analyze code, save the dist with the build record, publish to a PyPI-compatible index, and more:
# https://docs.microsoft.com/azure/devops/pipelines/languages/python

trigger:
  # tags:
  #   include:
  #     - '*'
  branches:
    include:
      - "main"
      - "release/*"
      # - "model_parallel_exp_support"  # temporarily add for specific feature branch validation
      - "refs/tags/*"
  paths:
    include:
      - "setup.*"  # setup.py
      - "requirements.txt"
      - "pyproject.toml"
      - ".codecov.yml"
      - "tests/**"
      - "src/**"
      - "requirements/**"
      - ".azure-pipelines/**"
      - ".actions/**"
pr:
  branches:
    include:
    - main
    - release/*
  paths:
    include:
      - "setup.*"  # setup.py
      - "requirements.txt"
      - "pyproject.toml"
      - ".codecov.yml"
      - "tests/**"
      - "src/**"
      - "requirements/**"
      - ".azure-pipelines/**"
      - ".actions/**"

jobs:
  - job: pytest
    strategy:
      matrix:
        'PyTorch | latest':
          image: "speediedan/finetuning-scheduler:py3.12-pt2.6.0-pl2.6-azpl-init"
          scope: ""
    # how long to run the job before automatically cancelling
    timeoutInMinutes: "100"
    # how much time to give 'run always even if cancelled tasks' before stopping them
    cancelTimeoutInMinutes: "2"

    pool: default

    container:
      image: $(image)
      mapDockerSocket: false
      volumes:
      - /var/run/user/998/docker.sock:/var/run/docker.sock
      options: --gpus all --shm-size=512m

    workspace:
      clean: outputs

    steps:

    - bash: |
        . /tmp/venvs/fts_dev/bin/activate
        pip install --upgrade pip requests setuptools
        pip install -e . --no-warn-script-location --requirement requirements/devel.txt
        # pip install lightning --upgrade # rather than upgrade, we now use the relevant pin
      env:
        USE_CI_COMMIT_PIN: "1"
      displayName: 'Install dependencies'

    - bash: |
        . /tmp/venvs/fts_dev/bin/activate
        python requirements/collect_env_details.py
        python -c "import torch ; print(f'PyTorch CUDA version: {torch.version.cuda}') ; mgpu = torch.cuda.device_count() ; assert mgpu >= 2, f'GPU: {mgpu}'"
      displayName: 'Env details'

    - bash: |
        . /tmp/venvs/fts_dev/bin/activate
        python -m coverage run --source src/finetuning_scheduler -m pytest src/finetuning_scheduler tests -v --junitxml=$(Build.Repository.LocalPath)/test-results.xml --durations=50
      displayName: 'Testing: standard'

    - bash: |
        . /tmp/venvs/fts_dev/bin/activate
        bash ./tests/special_tests.sh --mark_type=standalone --filter_pattern='test_f'
      displayName: 'Testing: standalone multi-gpu'

    # - bash: |
    #     . /tmp/venvs/fts_dev/bin/activate
    #     # bash ./tests/special_tests.sh --mark_type=exp_patch --filter_pattern='test_f' --experiment_patch_mask="1 0 0 1"
    #   displayName: 'Testing: Experimental Multi-GPU tests'

    - bash: |
        . /tmp/venvs/fts_dev/bin/activate
        python -m coverage report
        python -m coverage xml
        python -m coverage html
        curl -Os https://uploader.codecov.io/latest/linux/codecov
        chmod +x codecov
        ./codecov --token= $CODECOV_TOK --commit=$(Build.SourceVersion) --flags=gpu,pytest --name="GPU-coverage" --env=linux,azure
      env:
        CODECOV_TOK: $(CODECOV_TOKEN)  # explicit mapping required for secret azure pipeline variables
      displayName: 'Statistics'

    - bash: |
        set -e
        . /tmp/venvs/fts_dev/bin/activate
        python -m pytest src/fts_examples -v --maxfail=1 --durations=0 -W ignore:\`np.object\`:DeprecationWarning -W ignore:'`np.int` is':DeprecationWarning
      # condition: notIn(variables['scope'], '2.0.1')
      displayName: 'Testing: Examples'

    - bash: |
        . /tmp/venvs/fts_dev/bin/activate
        mkdir -p /__w/_temp/kernel_cache
        bash ./tests/special_tests.sh --mark_type=standalone --collect_dir='src/fts_examples' --filter_pattern='model_parallel_examples'
      # condition: notIn(variables['scope'], '2.0.1')
      env:
        PYTORCH_KERNEL_CACHE_PATH: "/__w/_temp/kernel_cache"
      displayName: 'Testing: Multi-GPU Examples'
