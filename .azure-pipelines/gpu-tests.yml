# Python package
# Create and test a Python package on multiple Python versions.
# Add steps that analyze code, save the dist with the build record, publish to a PyPI-compatible index, and more:
# https://docs.microsoft.com/azure/devops/pipelines/languages/python

trigger:
  # tags:
  #   include:
  #     - '*'
  branches:
    include:
      - "main"
      - "release/*"
      # - "model_parallel_exp_support"  # temporarily add for specific feature branch validation
      - "refs/tags/*"
  paths:
    include:
      - "setup.*"  # setup.py
      - "requirements.txt"
      - "pyproject.toml"
      - ".codecov.yml"
      - "tests/**"
      - "src/**"
      - "requirements/**"
      - ".azure-pipelines/**"
      - ".actions/**"
pr:
  branches:
    include:
    - main
    - release/*
  paths:
    include:
      - "setup.*"  # setup.py
      - "requirements.txt"
      - "pyproject.toml"
      - ".codecov.yml"
      - "tests/**"
      - "src/**"
      - "requirements/**"
      - ".azure-pipelines/**"
      - ".actions/**"
  drafts: false  # Only run for PRs that are "ready for review"

jobs:
  - job: pytest
    strategy:
      matrix:
        'PyTorch | latest':
          image: "speediedan/finetuning-scheduler:py3.13-pt2.10.0-pl2.6-azpl-init"
          scope: ""
    # how long to run the job before automatically cancelling
    timeoutInMinutes: "100"
    # how much time to give 'run always even if cancelled tasks' before stopping them
    cancelTimeoutInMinutes: "2"

    pool: default

    container:
      image: $(image)
      mapDockerSocket: false
      volumes:
      - /var/run/user/998/docker.sock:/var/run/docker.sock
      options: --gpus all --shm-size=512m

    workspace:
      clean: outputs

    steps:

    - bash: |
        set -e  # Exit on any error
        source /tmp/venvs/fts_dev/bin/activate

        echo "=== Pre-installed torch version ==="
        python -c "import torch; print(f'torch: {torch.__version__}')"

        echo "=== Installing finetuning-scheduler with locked dependencies ==="
        # Use UV_OVERRIDE for Lightning commit pinning
        # requirements.txt excludes torch (via --no-emit-package in lock script)
        # Use --exclude torch-excludes.txt to explicitly prevent torch from being reinstalled
        # (preserves the pre-installed CUDA torch from Docker image)
        export UV_OVERRIDE="${PWD}/requirements/ci/overrides.txt"
        if ! uv pip install -e . -r requirements/ci/requirements.txt --excludes /tmp/venvs/fts_dev/torch-excludes.txt; then
          echo "ERROR: Failed to install finetuning-scheduler with dependencies"
          exit 1
        fi
        echo "âœ“ Finetuning-scheduler installation completed"

        echo "=== Installed packages ==="
        uv pip list
      displayName: 'Install dependencies'

    - bash: |
        source /tmp/venvs/fts_dev/bin/activate
        python requirements/collect_env_details.py
        python -c "import torch ; print(f'PyTorch CUDA version: {torch.version.cuda}') ; mgpu = torch.cuda.device_count() ; assert mgpu >= 2, f'GPU: {mgpu}'"
      displayName: 'Env details'

    - bash: |
        source /tmp/venvs/fts_dev/bin/activate
        python -m coverage run --source src/finetuning_scheduler -m pytest src/finetuning_scheduler tests -v --junitxml=$(Build.Repository.LocalPath)/test-results.xml --durations=50
      displayName: 'Testing: standard'

    - bash: |
        source /tmp/venvs/fts_dev/bin/activate
        bash ./tests/special_tests.sh --mark_type=standalone --filter_pattern='test_f'
      displayName: 'Testing: standalone multi-gpu'

    # - bash: |
    #     source /tmp/venvs/fts_dev/bin/activate
    #     bash ./tests/special_tests.sh --mark_type=exp_patch --filter_pattern='test_f' --experiment_patch_mask="1 0 0 1"
    #   displayName: 'Testing: Experimental Multi-GPU'

    - bash: |
        source /tmp/venvs/fts_dev/bin/activate
        python -m coverage report
        python -m coverage xml
        python -m coverage html
        # curl -Os https://uploader.codecov.io/latest/linux/codecov

        curl https://keybase.io/codecovsecurity/pgp_keys.asc | gpg --no-default-keyring --keyring trustedkeys.gpg --import
        curl -Os https://cli.codecov.io/latest/linux/codecov
        curl -Os https://cli.codecov.io/latest/linux/codecov.SHA256SUM
        curl -Os https://cli.codecov.io/latest/linux/codecov.SHA256SUM.sig
        gpg --no-default-keyring --keyring trustedkeys.gpg --verify codecov.SHA256SUM.sig codecov.SHA256SUM
        shasum -a 256 -c codecov.SHA256SUM
        chmod +x codecov
        # ./codecov -t $CODECOV_TOK --commit=$(Build.SourceVersion) -F gpu -F pytest --name="GPU-coverage" --env=linux,azure
        ./codecov upload-process --slug 'speediedan/finetuning-scheduler' -t $CODECOV_TOK --commit-sha $(Build.SourceVersion) --git-service 'github' -n "GPU-coverage" -F gpu -F pytest --env 'linux,azure' -f 'coverage.xml'
      env:
        CODECOV_TOK: $(CODECOV_TOKEN)  # explicit mapping required for secret azure pipeline variables
      displayName: 'Statistics'

    - bash: |
        set -e
        source /tmp/venvs/fts_dev/bin/activate
        python -m pytest src/fts_examples -v --maxfail=1 --durations=0 -W ignore:\`np.object\`:DeprecationWarning -W ignore:'`np.int` is':DeprecationWarning
      # condition: notIn(variables['scope'], '2.0.1')
      displayName: 'Testing: Examples'

    - bash: |
        source /tmp/venvs/fts_dev/bin/activate
        mkdir -p /__w/_temp/kernel_cache
        bash ./tests/special_tests.sh --mark_type=standalone --collect_dir='src/fts_examples' --filter_pattern='model_parallel_examples'
      # condition: notIn(variables['scope'], '2.0.1')
      env:
        PYTORCH_KERNEL_CACHE_PATH: "/__w/_temp/kernel_cache"
      displayName: 'Testing: Multi-GPU Examples'

    - bash: |
        # since we use rootless docker and userns-remapping, we need to ensure all files/directories in previous
        # steps that may have been written with Azure's `az_pipeline_agent_azpcontainer` user (100997 in the host
        # subuid range) are chmod'd or removed
        echo "Adjusting ownership/permissions..."
        sudo chmod -R 775 /__w/1/s || true
        echo "Cleaning up ephemeral directories..."
        sudo rm -rf /__w/1/s/.pytest_cache || true
        echo 'Agent workspace cleanup completed'
      condition: always()
      displayName: 'Cleaning up agent workspace'
